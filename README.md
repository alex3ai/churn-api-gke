ü§ñ API de Predi√ß√£o de Churn com FastAPI e Docker
Este projeto implementa uma solu√ß√£o de ponta a ponta para um problema cl√°ssico de neg√≥cio: a predi√ß√£o de churn (cancelamento de servi√ßo) de clientes em uma empresa de telecomunica√ß√µes. O projeto abrange desde a an√°lise explorat√≥ria dos dados at√© o deploy de um modelo de Machine Learning como uma API web robusta e conteinerizada.
üéØ 1. O Problema de Neg√≥cio
A rotatividade de clientes (churn) √© uma m√©trica cr√≠tica para empresas de servi√ßo por assinatura, como as de telecomunica√ß√µes. Adquirir um novo cliente custa significativamente mais do que reter um existente.
O objetivo deste projeto √© construir um servi√ßo de Machine Learning que possa:
Prever com alta acur√°cia se um cliente est√° propenso a cancelar seu contrato.
Disponibilizar essa predi√ß√£o em tempo real atrav√©s de uma API, permitindo que outros sistemas (CRM, plataformas de marketing, etc.) tomem a√ß√µes proativas para reter o cliente.
üìä 2. An√°lise e Insights dos Dados (EDA)
A an√°lise explorat√≥ria (realizada no notebook An√°lise_churn_telco_customer.ipynb) revelou insights cruciais que guiaram a modelagem:
Dataset Desbalanceado: Aproximadamente 26.5% dos clientes na base de dados cancelaram o servi√ßo. Isso exigiu o uso de t√©cnicas como a estratifica√ß√£o na divis√£o dos dados e a escolha da m√©trica ROC AUC como principal avaliador de performance.
Fatores Comportamentais vs. Demogr√°ficos: A an√°lise demonstrou que o comportamento do cliente √© muito mais preditivo do que seus dados demogr√°ficos.
Principais Indicadores de Churn:
Tipo de Contrato: Clientes com contrato "M√™s a M√™s" t√™m uma taxa de churn drasticamente maior.
M√©todo de Pagamento: Pagamento via "Cheque Eletr√¥nico" est√° associado a um churn mais elevado.
Tempo de Contrato (Tenure): Clientes mais novos (baixo Tenure_Months) s√£o mais propensos a cancelar.
Servi√ßos de Prote√ß√£o: Clientes sem servi√ßos como Online_Security, Online_Backup e Tech_Support tendem a sair mais.
‚öôÔ∏è 3. Metodologia de Machine Learning
Para garantir um fluxo de trabalho robusto e replic√°vel (princ√≠pios de MLOps), foi utilizada uma Pipeline do Scikit-learn.
Pr√©-processamento (ColumnTransformer):
Vari√°veis Num√©ricas (Tenure_Months, Monthly_Charges, etc.): Passaram por uma padroniza√ß√£o utilizando StandardScaler.
Vari√°veis Categ√≥ricas (Contract, Payment_Method, etc.): Foram transformadas usando OneHotEncoder para converter as categorias em formato num√©rico.
Modelagem e Avalia√ß√£o:
Foram avaliados tr√™s modelos distintos: Regress√£o Log√≠stica, Random Forest e LightGBM.
O LightGBM foi selecionado como o modelo final devido √† sua excelente performance e efici√™ncia, atingindo uma pontua√ß√£o ROC AUC de 0.85 nos dados de teste, indicando um √≥timo poder preditivo.
Interpretabilidade do Modelo:
As features mais importantes para o modelo LightGBM foram Tenure_Months, Monthly_Charges e Contract, confirmando os insights da an√°lise explorat√≥ria.
üöÄ 4. Tecnologias Utilizadas
Python 3.9+
An√°lise e Modelagem: Pandas, Scikit-learn, LightGBM, Joblib
API: FastAPI (para alta performance) e Uvicorn
Containeriza√ß√£o: Docker e Docker Compose
Valida√ß√£o de Dados: Pydantic
üìÇ 5. Estrutura do Projeto
code
Code
/
|-- artifacts/            # Armazena o pipeline treinado (pipeline_lgbm.pkl)
|-- app/                  # C√≥digo fonte da API FastAPI
|   |-- main.py
|-- .dockerignore         # Arquivos a serem ignorados pelo Docker
|-- Dockerfile            # Instru√ß√µes para construir a imagem Docker
|-- requirements.txt      # Depend√™ncias Python do projeto
|-- README.md             # Esta documenta√ß√£o
|-- An√°lise_churn_telco_customer.ipynb  # Notebook com a an√°lise e treinamento do modelo
üíª 6. Como Executar a API Localmente
Pr√©-requisitos:
Git
Docker instalado e em execu√ß√£o.
Passos:
Clone o reposit√≥rio:
code
Bash
git clone https://github.com/SEU_USUARIO/NOME_DO_REPOSITORIO.git
cd NOME_DO_REPOSITORIO
Construa a imagem Docker:
Este comando l√™ o Dockerfile e monta a imagem da nossa aplica√ß√£o com todas as depend√™ncias.
code
Bash
docker build -t churn-api .
Execute o container:
Este comando inicia um container a partir da imagem, mapeando a porta 8000 da sua m√°quina para a porta 8000 do container.
code
Bash
docker run -d -p 8000:8000 --name churn-app churn-api
A API est√° pronta!
Voc√™ pode verificar se o container est√° rodando com docker ps.
üìñ 7. Endpoints da API
Ap√≥s iniciar o container, a API estar√° acess√≠vel em http://localhost:8000.
GET / - Health Check
Endpoint para verificar se a API est√° no ar e funcionando.
URL: http://localhost:8000
Resposta de Sucesso (200 OK):
code
JSON
{
  "status": "ok",
  "message": "API de Predi√ß√£o de Churn est√° no ar!"
}
POST /predict - Predi√ß√£o de Churn
Recebe os dados de um cliente em formato JSON e retorna a predi√ß√£o de churn e a probabilidade de confian√ßa.
URL: http://localhost:8000/predict
Corpo da Requisi√ß√£o (Exemplo):
code
JSON
{
  "Gender": "Female",
  "Senior_Citizen": "No",
  "Partner": "Yes",
  "Dependents": "No",
  "Tenure_Months": 1,
  "Phone_Service": "No",
  "Multiple_Lines": "Phone_service",
  "Internet_Service": "DSL",
  "Online_Security": "No",
  "Online_Backup": "Yes",
  "Device_Protection": "No",
  "Tech_Support": "No",
  "Streaming_TV": "No",
  "Streaming_Movies": "No",
  "Contract": "Month-to-month",
  "Paperless_Billing": "Yes",
  "Payment_Method": "Electronic_check",
  "Monthly_Charges": 29.85,
  "Total_Charges": 29.85
}
Resposta de Sucesso (200 OK):
code
JSON
{
  "predicao": "Sim",
  "probabilidade_de_confianca": "62.34%"
}
üìÑ Documenta√ß√£o Interativa (Swagger)
O FastAPI gera automaticamente uma documenta√ß√£o interativa. Voc√™ pode acess√°-la para visualizar todos os endpoints e test√°-los diretamente pelo navegador:
URL: http://localhost:8000/docs
üîÆ 8. Pr√≥ximos Passos
Este projeto serve como uma base s√≥lida. As pr√≥ximas etapas para evolu√≠-lo seriam:
Otimiza√ß√£o de Hiperpar√¢metros: Utilizar GridSearchCV ou RandomizedSearchCV para encontrar os melhores par√¢metros para o LightGBM e potencialmente aumentar a performance.
CI/CD: Implementar um pipeline de Integra√ß√£o e Entrega Cont√≠nua (usando GitHub Actions, por exemplo) para automatizar testes e deploys.
Deploy na Nuvem: Publicar a imagem Docker em um servi√ßo como Google Cloud Run, AWS Fargate ou Azure Container Instances para tornar a API publicamente acess√≠vel.
Monitoramento: Adicionar logging e monitoramento para acompanhar a performance do modelo e da API em produ√ß√£o.